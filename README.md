# ğŸš€ ML Deploy Demo â€“ FastAPI + Docker

A lightweight **FastAPI application** demonstrating how to deploy a simple machine learning pipeline inside a Docker container.  
The project showcases how to serve ML models or any Python backend service with FastAPI, following clean and reproducible deployment practices.

---

## ğŸ§± Project Overview

This repository demonstrates:
- âœ… Building a minimal and production-ready **Docker image** using `python:3.11-slim`
- âœ… Serving a **FastAPI API** (e.g., `/predict`, `/health`)
- âœ… Clean dependency management with `requirements.txt`
- âœ… Good logging practices, environment setup, and container orchestration readiness

---


## âš™ï¸ Setup & Local Development

### 1ï¸âƒ£ Create a virtual environment
```bash
python -m venv .venv
.\.venv\Scripts\activate      # Windows PowerShell
# source .venv/bin/activate   # macOS / Linux
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```
### 3ï¸âƒ£ Run locally (without Docker)
```bash
uvicorn app.main:app --reload
```
Then open ğŸ‘‰ http://localhost:8000/docs

Optional health check: http://localhost:8000/health

---

## ğŸ³ Run with Docker

### 1ï¸âƒ£ Build the image
```bash
docker build -t ml-deploy-demo .
```
### 2ï¸âƒ£ Run the container
```bash
docker run -d -p 8000:8000 --name ml-deploy-demo ml-deploy-demo:latest
```
### 3ï¸âƒ£ Test in your browser

Swagger UI: http://localhost:8000/docs

Optional health check: http://localhost:8000/health

---

# ğŸ‘¨â€ğŸ’» Author

Jan Dyndor

ğŸ’¼ AXA XL â€“ IDA Graduate Program

ğŸ¯ Aspiring Cloud AI Engineer | Python Backend | FastAPI | Azure | MLOps

ğŸ“§ [LinkedIn](https://www.linkedin.com/in/jan-dyndor)